const { OpenAIEmbeddings } = require('@langchain/openai');

// OpenAI ì„ë² ë”© í…ŒìŠ¤íŠ¸
async function testOpenAIEmbedding() {
  try {
    const embeddings = new OpenAIEmbeddings({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'text-embedding-3-small',
      dimensions: 1536,
    });

    const startTime = Date.now();
    const result = await embeddings.embedQuery('ë©”íƒ€ ê´‘ê³  ì •ì±…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”');
    const endTime = Date.now();

    console.log('ğŸ”µ OpenAI ì„ë² ë”© ê²°ê³¼:');
    console.log(`- ì°¨ì›: ${result.length}`);
    console.log(`- ì²˜ë¦¬ ì‹œê°„: ${endTime - startTime}ms`);
    console.log(`- ìƒ˜í”Œ: [${result.slice(0, 5).map(x => x.toFixed(4)).join(', ')}...]`);
    
    return {
      model: 'OpenAI text-embedding-3-small',
      dimension: result.length,
      processingTime: endTime - startTime,
      sample: result.slice(0, 5)
    };
  } catch (error) {
    console.error('âŒ OpenAI ì„ë² ë”© ì‹¤íŒ¨:', error.message);
    return null;
  }
}

// Ollama ì„ë² ë”© í…ŒìŠ¤íŠ¸
async function testOllamaEmbedding() {
  try {
    const response = await fetch('http://localhost:11434/api/embeddings', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'nomic-embed-text',
        prompt: 'ë©”íƒ€ ê´‘ê³  ì •ì±…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”',
      }),
    });

    if (!response.ok) {
      throw new Error(`Ollama API ì˜¤ë¥˜: ${response.status}`);
    }

    const startTime = Date.now();
    const data = await response.json();
    const endTime = Date.now();

    console.log('ğŸŸ¢ Ollama ì„ë² ë”© ê²°ê³¼:');
    console.log(`- ì°¨ì›: ${data.embedding.length}`);
    console.log(`- ì²˜ë¦¬ ì‹œê°„: ${endTime - startTime}ms`);
    console.log(`- ìƒ˜í”Œ: [${data.embedding.slice(0, 5).map(x => x.toFixed(4)).join(', ')}...]`);
    
    return {
      model: 'Ollama nomic-embed-text',
      dimension: data.embedding.length,
      processingTime: endTime - startTime,
      sample: data.embedding.slice(0, 5)
    };
  } catch (error) {
    console.error('âŒ Ollama ì„ë² ë”© ì‹¤íŒ¨:', error.message);
    return null;
  }
}

// ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async function main() {
  console.log('ğŸš€ ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n');

  const openaiResult = await testOpenAIEmbedding();
  console.log('');
  
  const ollamaResult = await testOllamaEmbedding();
  console.log('');

  // ê²°ê³¼ ë¹„êµ
  if (openaiResult && ollamaResult) {
    console.log('ğŸ“Š ì„±ëŠ¥ ë¹„êµ:');
    console.log('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
    console.log('â”‚ ëª¨ë¸            â”‚ ì°¨ì›        â”‚ ì²˜ë¦¬ì‹œê°„    â”‚ ë¹„ìš©        â”‚');
    console.log('â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤');
    console.log(`â”‚ OpenAI          â”‚ ${openaiResult.dimension.toString().padEnd(11)} â”‚ ${openaiResult.processingTime.toString().padEnd(11)}ms â”‚ ìœ ë£Œ         â”‚`);
    console.log(`â”‚ Ollama          â”‚ ${ollamaResult.dimension.toString().padEnd(11)} â”‚ ${ollamaResult.processingTime.toString().padEnd(11)}ms â”‚ ë¬´ë£Œ         â”‚`);
    console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
    
    console.log('\nğŸ¯ ì¶”ì²œ:');
    if (ollamaResult.processingTime < openaiResult.processingTime * 2) {
      console.log('âœ… Ollama ì¶”ì²œ - ì†ë„ì™€ ë¹„ìš© ë©´ì—ì„œ ìš°ìˆ˜');
    } else {
      console.log('âœ… OpenAI ì¶”ì²œ - ì •í™•ë„ì™€ ì†ë„ ë©´ì—ì„œ ìš°ìˆ˜');
    }
  }
}

main().catch(console.error);
