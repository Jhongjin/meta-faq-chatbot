/**
 * LLM (Large Language Model) ì„œë¹„ìŠ¤
 * Ollamaë¥¼ í†µí•œ ì „ë¬¸ì ì¸ ë‹µë³€ ìƒì„±
 */

export interface LLMResponse {
  answer: string;
  confidence: number;
  processingTime: number;
  model: string;
}

export interface LLMOptions {
  model?: string;
  temperature?: number;
  maxTokens?: number;
  systemPrompt?: string;
}

export class LLMService {
  private baseUrl: string;
  private defaultModel: string;
  private defaultOptions: LLMOptions;

  constructor() {
    // Ollama ì„¤ì • - ì™¸ë¶€ ì„œë²„ ì§€ì›
    this.baseUrl = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
    // ë” ë‚˜ì€ í’ˆì§ˆì˜ ëª¨ë¸ë¡œ ë³€ê²½: qwen2.5:7b (í’ˆì§ˆê³¼ ì†ë„ì˜ ê· í˜•)
    this.defaultModel = process.env.OLLAMA_MODEL || 'qwen2.5:7b';
    this.defaultOptions = {
      model: this.defaultModel,
      temperature: 0.3, // ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
      maxTokens: 2000, // ì¶©ë¶„í•œ ê¸¸ì´ì˜ êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ìœ„í•´ ì¦ê°€
      systemPrompt: this.getDefaultSystemPrompt()
    };
    
    console.log('ğŸ”§ LLMService ì´ˆê¸°í™”:', {
      baseUrl: this.baseUrl,
      model: this.defaultModel,
      isExternalServer: !this.baseUrl.includes('localhost')
    });
  }

  /**
   * ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  private getDefaultSystemPrompt(): string {
    return `ë‹¹ì‹ ì€ Meta(Facebook, Instagram) ê´‘ê³  ì •ì±…ê³¼ ê°€ì´ë“œë¼ì¸ì— ëŒ€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”
2. ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
3. ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
4. ê´€ë ¨ ì •ì±…ì´ë‚˜ ê°€ì´ë“œë¼ì¸ì´ ìˆë‹¤ë©´ ëª…ì‹œí•˜ì„¸ìš”
5. ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ë‚´ìš©ì€ ì†”ì§íˆ ë§ì”€í•˜ì„¸ìš”
6. ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
7. ë‹µë³€ì€ ë°˜ë“œì‹œ êµ¬ì¡°í™”ë˜ì–´ ìˆê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”
8. í•„ìš”ì‹œ ë‹¨ê³„ë³„ ì„¤ëª…ì´ë‚˜ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”

ë‹µë³€ í˜•ì‹ (í•œêµ­ì–´ë¡œë§Œ, ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”):
**í•µì‹¬ ë‹µë³€**
[ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œì‹œ]

**ìƒì„¸ ì„¤ëª…**
[êµ¬ì²´ì ì¸ ì„¤ëª…ì„ í•œêµ­ì–´ë¡œ ì œê³µ]

**ê´€ë ¨ ì •ì±…**
[ê´€ë ¨ ì •ì±…ì´ë‚˜ ì£¼ì˜ì‚¬í•­ì„ í•œêµ­ì–´ë¡œ ëª…ì‹œ]

**ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸**
[í•„ìš”ì‹œ ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸ì„ í•œêµ­ì–´ë¡œ ì œì‹œ]

ì£¼ì˜ì‚¬í•­:
- ì ˆëŒ€ ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ë‹µë³€ì„ ì¤‘ê°„ì— ëŠì§€ ë§ˆì„¸ìš”
- ëª¨ë“  ë‚´ìš©ì„ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”
- ë°˜ë“œì‹œ ìœ„ì˜ êµ¬ì¡°í™”ëœ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”`;
  }

  /**
   * Ollama API í˜¸ì¶œ
   */
  private async callOllamaAPI(
    prompt: string, 
    options: LLMOptions = {}
  ): Promise<LLMResponse> {
    const startTime = Date.now();
    
    // Vercel í™˜ê²½ì—ì„œëŠ” Ollamaê°€ ì‹¤í–‰ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ fallback ì‘ë‹µ
    if (process.env.VERCEL || process.env.NODE_ENV === 'production') {
      console.warn('í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ Ollama APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Fallback ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.');
      return this.generateFallbackResponse(prompt, options, startTime);
    }
    
    try {
      const requestOptions = { ...this.defaultOptions, ...options };
      
      const response = await fetch(`${this.baseUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: requestOptions.model,
          prompt: prompt,
          stream: false,
          options: {
            temperature: requestOptions.temperature,
            num_predict: requestOptions.maxTokens,
          }
        })
      });

      if (!response.ok) {
        throw new Error(`Ollama API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      const processingTime = Date.now() - startTime;

      return {
        answer: data.response || 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        confidence: this.calculateConfidence(data.response),
        processingTime,
        model: requestOptions.model || this.defaultModel
      };

    } catch (error) {
      console.error('Ollama API í˜¸ì¶œ ì‹¤íŒ¨:', error);
      return this.generateFallbackResponse(prompt, options, startTime);
    }
  }

  /**
   * Fallback ì‘ë‹µ ìƒì„± (Ollamaê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš°)
   */
  private generateFallbackResponse(
    prompt: string, 
    options: LLMOptions, 
    startTime: number
  ): LLMResponse {
    const processingTime = Date.now() - startTime;
    
    // ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
    const answer = this.generateSimpleResponse(prompt);
    
    return {
      answer,
      confidence: 0.3, // ë‚®ì€ ì‹ ë¢°ë„
      processingTime,
      model: options.model || this.defaultModel
    };
  }

  /**
   * ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
   */
  private generateSimpleResponse(prompt: string): string {
    const lowerPrompt = prompt.toLowerCase();
    
    if (lowerPrompt.includes('ê´‘ê³ ') && lowerPrompt.includes('ì •ì±…')) {
      return 'Meta ê´‘ê³  ì •ì±…ì— ëŒ€í•œ ì§ˆë¬¸ì´êµ°ìš”. í˜„ì¬ AI ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì¤‘ë‹¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ëŠ” Meta ê´‘ê³  ì •ì±… ë¬¸ì„œë¥¼ ì§ì ‘ í™•ì¸í•˜ì‹œê±°ë‚˜, ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.';
    }
    
    if (lowerPrompt.includes('facebook') || lowerPrompt.includes('instagram')) {
      return 'Facebookì´ë‚˜ Instagram ê´€ë ¨ ì§ˆë¬¸ì´êµ°ìš”. í˜„ì¬ AI ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì¤‘ë‹¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Meta ë¹„ì¦ˆë‹ˆìŠ¤ ë„ì›€ë§ ì„¼í„°ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ì‹œê±°ë‚˜, ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.';
    }
    
    if (lowerPrompt.includes('ìŠ¹ì¸') || lowerPrompt.includes('ê±°ë¶€')) {
      return 'ê´‘ê³  ìŠ¹ì¸ ê´€ë ¨ ì§ˆë¬¸ì´êµ°ìš”. ê´‘ê³  ìŠ¹ì¸ ê³¼ì •ì€ ë³µì¡í•˜ë©° ì—¬ëŸ¬ ìš”ì¸ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. í˜„ì¬ AI ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì¤‘ë‹¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, Meta ê´‘ê³  ì •ì±… ë¬¸ì„œë¥¼ ì§ì ‘ í™•ì¸í•˜ì‹œê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.';
    }
    
    return 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì¤‘ë‹¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Meta ê´‘ê³  ì •ì±… ê´€ë ¨ ì§ˆë¬¸ì€ ê´€ë¦¬ìì—ê²Œ ì§ì ‘ ë¬¸ì˜í•˜ì‹œê±°ë‚˜, Meta ë¹„ì¦ˆë‹ˆìŠ¤ ë„ì›€ë§ ì„¼í„°ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.';
  }

  /**
   * Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   */
  async checkOllamaStatus(): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/api/tags`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        }
      });

      return response.ok;
    } catch (error) {
      console.error('Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
      return false;
    }
  }

  /**
   * ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
   */
  async getAvailableModels(): Promise<string[]> {
    try {
      const response = await fetch(`${this.baseUrl}/api/tags`);
      const data = await response.json();
      
      return data.models?.map((model: any) => model.name) || [];
    } catch (error) {
      console.error('ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error);
      return [];
    }
  }

  /**
   * RAG ê¸°ë°˜ ì „ë¬¸ì ì¸ ë‹µë³€ ìƒì„±
   */
  async generateProfessionalAnswer(
    query: string,
    context: string,
    options: LLMOptions = {}
  ): Promise<LLMResponse> {
    const systemPrompt = options.systemPrompt || this.getDefaultSystemPrompt();
    
    const prompt = `${systemPrompt}

ë¬¸ì„œ ë‚´ìš©:
${context}

ì‚¬ìš©ì ì§ˆë¬¸: ${query}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.`;

    return await this.callOllamaAPI(prompt, options);
  }

  /**
   * ê³ í’ˆì§ˆ ë‹µë³€ ìƒì„± (í’ˆì§ˆ ìµœì í™”ëœ ì„¤ì •)
   */
  async generateFastAnswer(
    query: string,
    context: string
  ): Promise<LLMResponse> {
    const qualityOptions: LLMOptions = {
      model: 'qwen2.5:7b', // í’ˆì§ˆ ì¤‘ì‹¬ ëª¨ë¸
      temperature: 0.2, // ì¼ê´€ëœ ë‹µë³€
      maxTokens: 1500, // ì¶©ë¶„í•œ ê¸¸ì´ì˜ êµ¬ì¡°í™”ëœ ë‹µë³€
      systemPrompt: `ë‹¹ì‹ ì€ Meta(Facebook, Instagram) ê´‘ê³  ì •ì±…ê³¼ ê°€ì´ë“œë¼ì¸ì— ëŒ€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ í˜•ì‹ (í•œêµ­ì–´ë¡œë§Œ, ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”):
**í•µì‹¬ ë‹µë³€**
[ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œì‹œ]

**ìƒì„¸ ì„¤ëª…**
[êµ¬ì²´ì ì¸ ì„¤ëª…ì„ í•œêµ­ì–´ë¡œ ì œê³µ]

**ê´€ë ¨ ì •ì±…**
[ê´€ë ¨ ì •ì±…ì´ë‚˜ ì£¼ì˜ì‚¬í•­ì„ í•œêµ­ì–´ë¡œ ëª…ì‹œ]

**ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸**
[í•„ìš”ì‹œ ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸ì„ í•œêµ­ì–´ë¡œ ì œì‹œ]

ì£¼ì˜ì‚¬í•­:
- ì ˆëŒ€ ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ë‹µë³€ì„ ì¤‘ê°„ì— ëŠì§€ ë§ˆì„¸ìš”
- ëª¨ë“  ë‚´ìš©ì„ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”
- ë°˜ë“œì‹œ ìœ„ì˜ êµ¬ì¡°í™”ëœ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”`
    };

    return await this.generateProfessionalAnswer(query, context, qualityOptions);
  }

  /**
   * ê°„ë‹¨í•œ ì§ˆë¬¸ ë‹µë³€ ìƒì„±
   */
  async generateSimpleAnswer(
    query: string,
    options: LLMOptions = {}
  ): Promise<LLMResponse> {
    const systemPrompt = `ë‹¹ì‹ ì€ Meta ê´‘ê³  ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.`;
    
    const prompt = `${systemPrompt}

ì§ˆë¬¸: ${query}

ë‹µë³€:`;

    return await this.callOllamaAPI(prompt, options);
  }

  /**
   * ë‹µë³€ ì‹ ë¢°ë„ ê³„ì‚°
   */
  private calculateConfidence(response: string): number {
    if (!response || response.length < 10) return 0.1;
    
    // ë‹µë³€ ê¸¸ì´ ê¸°ë°˜ ì‹ ë¢°ë„
    let confidence = 0.5;
    
    // êµ¬ì²´ì ì¸ ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš° ì‹ ë¢°ë„ ì¦ê°€
    if (response.includes('ì •ì±…') || response.includes('ê°€ì´ë“œë¼ì¸')) confidence += 0.1;
    if (response.includes('Meta') || response.includes('Facebook') || response.includes('Instagram')) confidence += 0.1;
    if (response.includes('ê´‘ê³ ') || response.includes('advertising')) confidence += 0.1;
    
    // ë¶ˆí™•ì‹¤í•œ í‘œí˜„ì´ ìˆëŠ” ê²½ìš° ì‹ ë¢°ë„ ê°ì†Œ
    if (response.includes('ëª¨ë¥´ê² ìŠµë‹ˆë‹¤') || response.includes('í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')) confidence -= 0.2;
    if (response.includes('ì¶”ì¸¡') || response.includes('ì•„ë§ˆë„')) confidence -= 0.1;
    
    return Math.max(0.1, Math.min(0.9, confidence));
  }

  /**
   * ë‹µë³€ í’ˆì§ˆ ê²€ì¦
   */
  validateAnswer(answer: string, query: string): {
    isValid: boolean;
    issues: string[];
    suggestions: string[];
  } {
    console.log('ğŸ” ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ì‹œì‘:', { answer: answer.substring(0, 100) + '...', query });
    const issues: string[] = [];
    const suggestions: string[] = [];

    // ê¸°ë³¸ ê²€ì¦
    if (!answer || answer.trim().length < 10) {
      issues.push('ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.');
      suggestions.push('ë” êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.');
    }

    if (answer.includes('ì£„ì†¡í•©ë‹ˆë‹¤') && answer.includes('ì˜¤ë¥˜')) {
      issues.push('ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      suggestions.push('ì •ìƒì ì¸ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.');
    }

    // í•œêµ­ì–´ ë¹„ìœ¨ í™•ì¸
    const koreanChars = (answer.match(/[\u3131-\u3163\uac00-\ud7a3]/g) || []).length;
    const totalChars = answer.replace(/\s/g, '').length;
    const koreanRatio = totalChars > 0 ? koreanChars / totalChars : 0;

    // ì˜ì–´ ë¹„ìœ¨ í™•ì¸
    const englishChars = (answer.match(/[a-zA-Z]/g) || []).length;
    const englishRatio = totalChars > 0 ? englishChars / totalChars : 0;

    // í•œêµ­ì–´ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ (êµ¬ì¡°í™”ëœ ë‹µë³€ ê¸°ì¤€)
    if (koreanRatio >= 0.7 && englishRatio <= 0.3) {
      // í•œêµ­ì–´ê°€ 70% ì´ìƒì´ê³  ì˜ì–´ê°€ 30% ì´í•˜ë©´ í’ˆì§ˆì´ ì¢‹ë‹¤ê³  íŒë‹¨
      const hasStructure = answer.includes('**') && (answer.includes('í•µì‹¬') || answer.includes('ìƒì„¸') || answer.includes('ì •ì±…'));
      const hasContent = answer.length > 100; // ì¶©ë¶„í•œ ê¸¸ì´ì˜ ë‹µë³€
      
      if (hasStructure && hasContent) {
        return {
          isValid: true,
          issues: [],
          suggestions: []
        };
      }
    }

    // ì–¸ì–´ ê´€ë ¨ ì´ìŠˆ (êµ¬ì¡°í™”ëœ ë‹µë³€ ê¸°ì¤€)
    if (koreanRatio < 0.5) {
      issues.push('ë‹µë³€ì´ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      suggestions.push('í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
    }

    if (englishRatio > 0.5) {
      issues.push('ë‹µë³€ì— ì˜ì–´ê°€ ë„ˆë¬´ ë§ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      suggestions.push('í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
    }

    // êµ¬ì¡° ê´€ë ¨ ì´ìŠˆ (êµ¬ì¡°í™”ëœ ë‹µë³€ í•„ìˆ˜)
    if (!answer.includes('**') && !answer.includes('í•µì‹¬') && !answer.includes('ìƒì„¸') && !answer.includes('ì •ì±…')) {
      issues.push('ë‹µë³€ì´ êµ¬ì¡°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      suggestions.push('êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
    }

    // ê´€ë ¨ì„± ê²€ì¦ (ë” ê´€ëŒ€í•˜ê²Œ)
    const queryKeywords = query.toLowerCase().split(' ').filter(word => word.length > 2);
    const answerKeywords = answer.toLowerCase().split(' ').filter(word => word.length > 2);
    
    const relevantKeywords = queryKeywords.filter(keyword => 
      answerKeywords.some(answerKeyword => 
        answerKeyword.includes(keyword) || keyword.includes(answerKeyword)
      )
    );

    if (relevantKeywords.length < queryKeywords.length * 0.2) {
      issues.push('ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê´€ë ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤.');
      suggestions.push('ì§ˆë¬¸ê³¼ ë” ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.');
    }

    const result = {
      isValid: issues.length === 0,
      issues,
      suggestions
    };
    
    console.log('ğŸ” ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ê²°ê³¼:', {
      isValid: result.isValid,
      issues: result.issues,
      koreanRatio: totalChars > 0 ? (koreanChars / totalChars).toFixed(2) : 0,
      englishRatio: totalChars > 0 ? (englishChars / totalChars).toFixed(2) : 0,
      answerLength: answer.length
    });
    
    return result;
  }
}

export const llmService = new LLMService();
