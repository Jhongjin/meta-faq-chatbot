import { NextRequest, NextResponse } from 'next/server';
import { generateResponse, getAvailableModels, checkOllamaHealth } from '@/lib/services/ollama';

// ê¸°ë³¸ í—¤ë” ì„¤ì •
const headers = {
  'Content-Type': 'application/json',
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
  'Access-Control-Allow-Headers': 'Content-Type',
};

// OPTIONS ë©”ì„œë“œ
export async function OPTIONS() {
  return new NextResponse(null, {
    status: 200,
    headers,
  });
}

// GET ë©”ì„œë“œ - Ollama ì„œë²„ ìƒíƒœ ë° ëª¨ë¸ ëª©ë¡ í™•ì¸
export async function GET() {
  try {
    console.log('ğŸ” Ollama API GET ìš”ì²­ - ì„œë²„ ìƒíƒœ í™•ì¸');
    
    // í™˜ê²½ ë³€ìˆ˜ ì§ì ‘ í™•ì¸
    const ollamaUrl = process.env.OLLAMA_BASE_URL;
    console.log('ğŸ”§ í™˜ê²½ ë³€ìˆ˜ ì§ì ‘ í™•ì¸:', {
      OLLAMA_BASE_URL: ollamaUrl,
      NODE_ENV: process.env.NODE_ENV,
      hasOllamaUrl: !!ollamaUrl,
      allEnvKeys: Object.keys(process.env).filter(key => key.includes('OLLAMA')),
      allEnvKeysCount: Object.keys(process.env).length
    });
    
    // í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (Nginx í”„ë¡ì‹œë¥¼ í†µí•´ ì ‘ê·¼)
    const baseUrl = ollamaUrl || 'http://141.164.52.52';
    console.log('ğŸ”§ ì‚¬ìš©í•  Ollama URL:', baseUrl);
    
    // ì§ì ‘ URLë¡œ í—¬ìŠ¤ ì²´í¬
    let isHealthy = false;
    let models = [];
    
    try {
      console.log('ğŸ” Ollama ì„œë²„ í—¬ìŠ¤ ì²´í¬:', baseUrl);
      
      // íƒ€ì„ì•„ì›ƒ ì„¤ì • (60ì´ˆ)
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 60000);
      
      const healthResponse = await fetch(`${baseUrl}/api/tags`, {
        signal: controller.signal,
        headers: {
          'Accept': 'application/json',
          'Content-Type': 'application/json'
        }
      });
      
      clearTimeout(timeoutId);
      
      isHealthy = healthResponse.ok;
      console.log('ğŸ” í—¬ìŠ¤ ì²´í¬ ê²°ê³¼:', { 
        isHealthy, 
        status: healthResponse.status,
        statusText: healthResponse.statusText,
        url: baseUrl
      });
      
      if (isHealthy) {
        try {
          const modelsResponse = await fetch(`${baseUrl}/api/tags`, {
            signal: controller.signal,
            headers: {
              'Accept': 'application/json',
              'Content-Type': 'application/json'
            }
          });
          
          if (modelsResponse.ok) {
            const modelsData = await modelsResponse.json();
            models = modelsData.models || [];
            console.log('ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:', models);
          } else {
            console.error('âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', modelsResponse.status, modelsResponse.statusText);
            models = [];
          }
        } catch (error) {
          console.error('âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜:', error);
          models = [];
        }
      } else {
        console.error('âŒ ì„œë²„ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨:', {
          status: healthResponse.status,
          statusText: healthResponse.statusText,
          url: baseUrl
        });
      }
    } catch (error) {
      console.error('âŒ Ollama ì„œë²„ ì—°ê²° ì˜¤ë¥˜:', {
        error: error.message,
        name: error.name,
        url: baseUrl
      });
      isHealthy = false;
    }
    
    const response = {
      success: true,
      message: 'Ollama APIê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.',
      timestamp: new Date().toISOString(),
      server: {
        healthy: isHealthy,
        baseUrl: baseUrl,
        actualUrl: baseUrl,
        availableModels: models.map(model => ({
          name: model.name,
          size: `${(model.size / 1024 / 1024 / 1024).toFixed(2)}GB`,
          modifiedAt: model.modified_at
        }))
      },
      methods: ['GET', 'POST', 'OPTIONS'],
      version: 'ollama-v1',
      endpoint: '/api/ollama'
    };

    console.log('ğŸ“¤ ìµœì¢… API ì‘ë‹µ:', {
      success: response.success,
      serverHealthy: response.server.healthy,
      modelsCount: response.server.availableModels.length
    });

    return NextResponse.json(response, {
      status: 200,
      headers,
    });
  } catch (error) {
    console.error('âŒ Ollama API GET ìš”ì²­ ì˜¤ë¥˜:', error);
    
    return NextResponse.json({
      success: false,
      error: 'Ollama ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      details: error instanceof Error ? error.message : String(error),
      server: {
        healthy: false,
        baseUrl: process.env.OLLAMA_BASE_URL || 'http://141.164.52.52'
      }
    }, {
      status: 500,
      headers,
    });
  }
}

// POST ë©”ì„œë“œ - Ollamaë¥¼ í†µí•œ ì‘ë‹µ ìƒì„±
export async function POST(request: NextRequest) {
  console.log('ğŸš€ Ollama API POST ìš”ì²­ ì‹œì‘');
  
  try {
    // ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
    const body = await request.json();
    const { message, model = 'tinyllama:1.1b' } = body;

    if (!message || typeof message !== 'string' || message.trim().length === 0) {
      return NextResponse.json({
        success: false,
        error: 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
        details: 'ìœ íš¨í•œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
      }, {
        status: 400,
        headers,
      });
    }

    console.log(`ğŸ’¬ Ollama API ë©”ì‹œì§€ ìˆ˜ì‹ : "${message}" (ëª¨ë¸: ${model})`);

    // í™˜ê²½ ë³€ìˆ˜ì—ì„œ URL ê°€ì ¸ì˜¤ê¸° (Nginx í”„ë¡ì‹œë¥¼ í†µí•´ ì ‘ê·¼)
    const ollamaUrl = process.env.OLLAMA_BASE_URL || 'http://141.164.52.52';
    console.log('ğŸ”§ POST ìš”ì²­ì—ì„œ ì‚¬ìš©í•  Ollama URL:', ollamaUrl);

    // Ollama ì„œë²„ ìƒíƒœ í™•ì¸
    let isHealthy = false;
    try {
      const healthResponse = await fetch(`${ollamaUrl}/api/tags`);
      isHealthy = healthResponse.ok;
      console.log('ğŸ” POST ìš”ì²­ í—¬ìŠ¤ ì²´í¬ ê²°ê³¼:', { isHealthy, status: healthResponse.status });
    } catch (error) {
      console.error('âŒ POST ìš”ì²­ í—¬ìŠ¤ ì²´í¬ ì˜¤ë¥˜:', error);
    }

    if (!isHealthy) {
      return NextResponse.json({
        success: false,
        error: 'Ollama ì„œë²„ ì—°ê²° ì˜¤ë¥˜',
        details: 'Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.'
      }, {
        status: 503,
        headers,
      });
    }

    // Ollamaë¥¼ í†µí•œ ì‘ë‹µ ìƒì„±
    const startTime = Date.now();
    const response = await generateResponse(message.trim(), model);
    const processingTime = Date.now() - startTime;

    console.log('âœ… Ollama ì‘ë‹µ ì™„ë£Œ');

    const apiResponse = {
      success: true,
      response: {
        message: response,
        model: model,
        processingTime: processingTime,
        server: 'Ollama (Vultr)',
        timestamp: new Date().toISOString()
      }
    };

    console.log('ğŸ“¤ Ollama API ì‘ë‹µ ì „ì†¡');
    return NextResponse.json(apiResponse, {
      status: 200,
      headers,
    });

  } catch (error) {
    console.error('âŒ Ollama API POST ìš”ì²­ ì˜¤ë¥˜:', error);
    
    return NextResponse.json({
      success: false,
      error: 'Ollama ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      details: error instanceof Error ? error.message : String(error)
    }, {
      status: 500,
      headers,
    });
  }
}
