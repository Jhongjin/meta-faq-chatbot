/**
 * ë¬¸ì„œ ì¸ë±ì‹± ì„œë¹„ìŠ¤
 * í¬ë¡¤ë§ëœ ì½˜í…ì¸ ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¸ë±ì‹±
 */

import { createClient } from '@supabase/supabase-js';

export interface DocumentMetadata {
  source: string;
  title: string;
  type: string;
  lastUpdated: string;
  contentLength: number;
  crawledAt: string;
}

export class DocumentIndexingService {
  private supabase;

  constructor() {
    this.supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!,
      {
        auth: { persistSession: false },
        db: { schema: 'public' }
      }
    );
  }

  async indexCrawledContent(
    url: string, 
    content: string, 
    title: string, 
    metadata: DocumentMetadata
  ): Promise<void> {
    try {
      console.log(`ğŸ“š ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘: ${title}`);

      // ë¬¸ì„œ ID ìƒì„±
      const documentId = `crawled_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

      // ë¬¸ì„œ ì €ì¥
      const { error: docError } = await this.supabase
        .from('documents')
        .insert({
          id: documentId,
          title: title,
          content: content,
          type: 'url',
          status: 'processing',
          chunk_count: 0,
          file_size: content.length,
          file_type: 'text/plain',
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString(),
          url: url
        });

      if (docError) {
        throw new Error(`ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: ${docError.message}`);
      }

      // í…ìŠ¤íŠ¸ ì²­í‚¹
      const chunks = this.chunkText(content, url);
      console.log(`ğŸ“ ì²­í¬ ìƒì„±: ${chunks.length}ê°œ`);

      // ì²­í¬ ì €ì¥
      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        
        const { error: chunkError } = await this.supabase
          .from('document_chunks')
          .insert({
            id: `${documentId}_chunk_${i}`,
            document_id: documentId,
            chunk_id: i,
            content: chunk,
            embedding: new Array(768).fill(0), // ì„ì‹œ ì„ë² ë”©
            created_at: new Date().toISOString()
          });

        if (chunkError) {
          console.error(`ì²­í¬ ${i} ì €ì¥ ì‹¤íŒ¨:`, chunkError);
        }
      }

      // ë¬¸ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
      const { error: updateError } = await this.supabase
        .from('documents')
        .update({
          status: 'indexed',
          chunk_count: chunks.length,
          updated_at: new Date().toISOString()
        })
        .eq('id', documentId);

      if (updateError) {
        console.error(`ë¬¸ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:`, updateError);
      }

      console.log(`âœ… ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ: ${title} (${chunks.length}ê°œ ì²­í¬)`);

    } catch (error) {
      console.error(`âŒ ë¬¸ì„œ ì¸ë±ì‹± ì‹¤íŒ¨: ${title}`, error);
      throw error;
    }
  }

  private chunkText(text: string, source: string): string[] {
    const maxChunkSize = 1000;
    const overlap = 200;
    const chunks: string[] = [];

    let start = 0;
    while (start < text.length) {
      const end = Math.min(start + maxChunkSize, text.length);
      let chunk = text.slice(start, end);

      // ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
      if (end < text.length) {
        const lastSentenceEnd = chunk.lastIndexOf('.');
        if (lastSentenceEnd > maxChunkSize * 0.5) {
          chunk = chunk.slice(0, lastSentenceEnd + 1);
        }
      }

      chunks.push(chunk.trim());
      start = end - overlap;
    }

    return chunks.filter(chunk => chunk.length > 50);
  }
}